{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "from glob import glob\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from helper import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraction of classes\n",
    "We will be classifying images based on US State\n",
    "This info is contained within the metadata file aquired with the images\n",
    "\n",
    "The original metadata file is quite large so we will aim to reduce it asap, by only retaining images we are using for this project\n",
    "The method used is not very fast however, but since it will only be done once for preprocessing it is deemed acceptable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageList = os.listdir(\"data\")\n",
    "classes = ['FL', 'CA', 'NM', 'ME']\n",
    "out_dir = \"processed\"\n",
    "imgDir = \"images\"\n",
    "images = []\n",
    "\n",
    "# Notebook Settings\n",
    "resampleToggle = False\n",
    "repeatMeta = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "if repeatMeta:\n",
    "    metadata = pd.read_csv(\"metadata.csv\", engine='python')\n",
    "    metadataShort = pd.DataFrame(columns=metadata.columns)\n",
    "\n",
    "    for i in tqdm(imageList):\n",
    "        relMeta = metadata.loc[metadata['NAIP Entity ID'].str.contains(i[:15], case=False)].drop_duplicates(subset=['State'], keep='last')\n",
    "        relMeta = relMeta.loc[relMeta['State'].isin(classes)]   #Check if acceptable class\n",
    "        metadataShort = metadataShort.append(relMeta, ignore_index = True)   #For record\n",
    "\n",
    "    metadataShort.to_csv(\"metadataShort.csv\")\n",
    "    del metadata, relMeta  #To clear up memory \n",
    "\n",
    "else:\n",
    "    metadataShort = pd.read_csv(\"metadataShort.csv\", engine='python')\n",
    "\n",
    "\n",
    "idAll = metadataShort[\"NAIP Entity ID\"]\n",
    "labelAll = metadataShort[\"State\"]\n",
    "\n",
    "## FOR RUTURE CREATE PRE-SPLIT BASED ON ROOT IMAGE (to avoid giving the ai \"learned images\")\n",
    "## Would only need it for the final Test set, the training & Validation data should be ok... but could be splt too\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "id_vali, id_test, lab_vali, lab_test = train_test_split(idAll, labelAll, stratify=labelAll, test_size=0.15)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadataShort.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sample import sample_images\n",
    "\n",
    "if resampleToggle:\n",
    "    for c,img in enumerate(tqdm(imageList)):\n",
    "        try:\n",
    "            \n",
    "            #image = extractImage(\"data/\",img,\"dataHuman/\")\n",
    "            image = extractImage(\"data/\",img)\n",
    "            samples,corners = sample_images([image], 20, [128,128,4], 20)\n",
    "            if c in id_test.index:\n",
    "                tT = \"test\"\n",
    "            else:\n",
    "                tT = \"train\"\n",
    "            for i, (sample, corner) in enumerate(zip(samples, corners)):\n",
    "                    export_name = f\"{labelAll[c]}_{c}_{i}\"\n",
    "                    h5_file = h5py.File(f\"{out_dir}/{tT}/{export_name}.h5\", \"w-\")\n",
    "                    dset = h5_file.create_dataset(\"IMG\", sample[0].shape, compression=\"gzip\")\n",
    "                    dset[...] = sample[0]\n",
    "                    dset.attrs[\"x\"] = corner[0]\n",
    "                    dset.attrs[\"y\"] = corner[1]\n",
    "                    dset.attrs[\"z\"] = corner[2]\n",
    "                    h5_file.close()\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from numpy.random import randint\n",
    "\n",
    "sampleList = os.listdir(\"processed/train/\")\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(16):\n",
    "    ax = plt.subplot(4, 4, i + 1)\n",
    "\n",
    "    sel = sampleList[randint(0, len(sampleList))]\n",
    "    img = load_sample(\"processed/train/\" + sel)\n",
    "    img = imgRGBConverter(img)\n",
    "\n",
    "    plt.imshow(img.astype(\"uint8\"))\n",
    "    plt.title(str(sel[:2]))\n",
    "    plt.axis(\"off\")\n",
    "plt.savefig(imgDir + \"/RandomSelection.jpg\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LOAD DATA FOR SPLITTING\n",
    "\n",
    "#Training and validation come from the same sampled images \n",
    "img_train, lab_train = sampleLoader(\"processed/train/\",classes)\n",
    "img_train, img_vali, lab_train, lab_vali = train_test_split(img_train, lab_train, stratify=lab_train, test_size=0.3)\n",
    "\n",
    "#Testing images are specificaly ones that have never been sampled\n",
    "#Therefore it checks the generality of the network\n",
    "img_test, lab_test = sampleLoader(\"processed/test/\",classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## START UP TF CUDA\n",
    "import tensorflow as tf \n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "assert len(gpus) > 0\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((img_train, lab_train)).batch(batch_size).shuffle(len(img_train), reshuffle_each_iteration=True).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((img_vali, lab_vali)).batch(batch_size).shuffle(len(img_vali), reshuffle_each_iteration=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, Sequential\n",
    "\n",
    "num_classes = len(classes)\n",
    "img_height = 128\n",
    "img_width = 128\n",
    "\n",
    "data_augmentation = Sequential(\n",
    "  [\n",
    "  layers.RandomFlip(), \n",
    "  layers.RandomRotation(0.1), \n",
    "  ]\n",
    ")\n",
    "\n",
    "model = Sequential([\n",
    "  data_augmentation,\n",
    "  layers.Rescaling(1./255, input_shape=(img_height, img_width, 4)),\n",
    "  layers.Conv2D(16, 4, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 4, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(64, 4, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Flatten(),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(num_classes)\n",
    "])\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=200\n",
    "history = model.fit(\n",
    "  train_dataset,\n",
    "  validation_data=test_dataset,\n",
    "  epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.savefig(imgDir + \"/TrainingData.jpg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "randomlist = random.sample(range(0, len(img_test)), 4)\n",
    "\n",
    "cor = 0\n",
    "k = 1\n",
    "plt.figure(figsize=(16, 8))\n",
    "\n",
    "\n",
    "for i in range(0,len(img_test)):\n",
    "\n",
    "    img_array = tf.expand_dims(img_test[i], 0) # Create a batch\n",
    "    predictions = model.predict(img_array)\n",
    "    score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "    if np.argmax(score) == lab_test[i]:\n",
    "        cor += 1 \n",
    "\n",
    "    if i in randomlist:\n",
    "\n",
    "        plt.subplot(2,4,k)\n",
    "        img = imgRGBConverter(img_test[i])\n",
    "        plt.imshow(img.astype(\"uint8\"))\n",
    "        plt.title(\"Class: {}, Predicted {}\"\n",
    "                .format(classes[lab_test[i]],classes[np.argmax(score)]))\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        plt.subplot(2,4,k+4)\n",
    "        plt.bar(classes,predictions[0])\n",
    "        plt.title(\"{:.2f} confidence\".format( 100 * np.max(score)))\n",
    "        \n",
    "        k += 1\n",
    "\n",
    "print(\"----------------------------------------------------\")\n",
    "print(\"Unseen Test Set accuracy: {}\".format(cor/len(img_test)*100))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(imgDir + \"/Testing.jpg\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e88cafe56aac1a4c020faadd1d7e8ebb3c59c3a109c2c612618c23420c032c8d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
